# ITER-20260220-01

## Objetivo y contexto
Refactor completo de `docs/tutorials/03-sagemaker-pipeline.md` para convertir la fase 03 en un workshop notebook-first, con `sagemaker` v3 como camino principal y referencias explicitas a la documentacion oficial de SageMaker (`docs/aws/sagemaker-dg.pdf`).

## Decisiones tecnicas y alternativas descartadas
1. Se adopta ejecucion notebook-first para la fase 03.
2. Se fija politica SDK-first:
   - `sagemaker` v3 como API principal,
   - `boto3` solo como fallback operacional y diagnostico.
3. Se agrega bloque de referencias DG para trazabilidad tecnica.
4. Se incorpora operacion core de Pipelines:
   - step caching,
   - `RetryPipelineExecution`,
   - triage por estado de steps.
5. Se mantiene separacion Terraform vs runtime:
   - Terraform despliega recursos estables,
   - el pipeline crea jobs/artefactos/model package versions en runtime.
6. Alternativas descartadas:
   - mantener tutorial puramente CLI,
   - mantener troubleshooting solo narrativo sin tabla sintoma->accion,
   - mezclar serving de fase 04 dentro de fase 03.

## IAM usado (roles/policies/permisos clave)
1. Identidad operativa humana: `data-science-user`.
2. Perfil AWS CLI: `data-science-user`.
3. Role de ejecucion del pipeline: role dedicado de fase 03 (consumido desde `SAGEMAKER_PIPELINE_ROLE_ARN` en notebook).
4. Permisos clave esperados en role de pipeline:
   - `s3:GetObject`, `s3:ListBucket` para inputs y code bundle,
   - `s3:PutObject` para artefactos runtime,
   - acciones SageMaker para processing/training/evaluation/register,
   - logs de CloudWatch,
   - `iam:PassRole` acotado.

## Comandos ejecutados y resultado esperado
Comandos usados para validar la actualizacion documental:

1. Revisar secciones del tutorial:
```bash
rg -n '^## ' docs/tutorials/03-sagemaker-pipeline.md
```

2. Verificar contrato de parametros:
```bash
rg -n 'CodeBundleUri|InputTrainUri|InputValidationUri|AccuracyThreshold' docs/tutorials/03-sagemaker-pipeline.md
```

3. Verificar cobertura de operacion y control de flujo:
```bash
rg -n 'RetryPipelineExecution|ListPipelineExecutionSteps|ConditionStep|RegisterModel' docs/tutorials/03-sagemaker-pipeline.md
```

Resultado esperado:
1. El tutorial contiene las secciones reordenadas del plan.
2. El contrato de parametros aparece de forma consistente.
3. Existen referencias explicitas a retry, monitoreo de steps y gating.

## Evidencia
Archivos modificados:
1. `docs/tutorials/03-sagemaker-pipeline.md`
2. `docs/iterations/ITER-20260220-01.md`

Evidencia funcional agregada en el tutorial:
1. Seccion de fuentes DG con URLs de Pipelines, APIs de ejecucion y Model Registry.
2. Blueprint de notebook por celdas (00 a 11) con `ProcessingStep`, `TrainingStep`, `ConditionStep`, `RegisterModel`.
3. Bloque de operacion avanzada con cache, retry y triage por estado.
4. Troubleshooting en tabla sintoma->causa->accion.

## Riesgos/pendientes
1. En el estado actual del repo, `pipeline/code/` no muestra los scripts fuente esperados (`preprocess.py`, `evaluate.py`, `train.py`); sin eso, la ejecucion real del workshop no es reproducible.
2. Si cambia el esquema de `evaluation.json`, puede fallar el `ConditionStep` por `JsonGet`.
3. Pendiente validar en ejecucion real que todos los permisos IAM de runtime queden cubiertos en ambiente objetivo.

## Proximo paso
1. Crear o restaurar scripts fuente en `pipeline/code/`.
2. Ejecutar el workshop en notebook con perfil `data-science-user`.
3. Capturar evidencia de corrida real (`PipelineExecutionArn`, estado por step, `ModelPackageArn`) en una nueva iteracion.
