# ITER-20260217-02

## Objetivo
Alinear los tutoriales al flujo end-to-end objetivo (ModelBuild -> Model Registry -> ModelDeploy con staging/manual approval/prod) y preparar datos base reales de Titanic.

## Cambios
- Se actualizo `docs/tutorials/README.md` con diagrama Mermaid que refleja:
  - ModelBuild CI pipeline,
  - registro de modelo en SageMaker Model Registry,
  - ModelDeploy CD pipeline con `staging`, gate manual y `prod`,
  - orquestacion por EventBridge + Step Functions + Lambda.
- Se reforzaron fases `00` a `07` para aterrizar el flujo objetivo en decisiones, comandos y evidencia esperada.
- Se descargo dataset Titanic fuente:
  - `data/titanic/raw/titanic.csv`
- Se generaron datasets de entrenamiento y validacion:
  - `data/titanic/splits/train.csv`
  - `data/titanic/splits/validation.csv`
- Se agrego `scripts/prepare_titanic_splits.py` para regenerar split de forma deterministica.

## Evidencia
- Conteos de filas:
  - `data/titanic/raw/titanic.csv`: 892 lineas (incluye header)
  - `data/titanic/splits/train.csv`: 714 lineas
  - `data/titanic/splits/validation.csv`: 179 lineas
- Script de split ejecutado exitosamente con semilla fija (`seed=42`).

## Decisiones
- Se uso como dataset fuente el CSV publico de Titanic (DataScienceDojo) para mantener reproducibilidad simple.
- El split train/validation se define estratificado por `Survived` y deterministico.
- Se mantiene equivalencia funcional con la imagen de referencia usando stack del proyecto (`GitHub Actions` + `Terraform`).

## Riesgos
- El dataset fuente depende de disponibilidad de URL publica.
- Si cambia el esquema del CSV fuente, se debe revisar el script de split.

## Siguiente paso
Subir `raw/train/validation` a S3 por entorno y validar ejecucion de pipeline SageMaker con estos artefactos.
