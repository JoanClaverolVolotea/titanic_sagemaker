# ITER-20260220-02

## Objetivo y contexto
Implementar y ejecutar de forma real la fase 03 (`docs/tutorials/03-sagemaker-pipeline.md`) con identidad `data-science-user`, dejando el pipeline `titanic-modelbuild-dev` operativo end-to-end hasta registro en Model Registry.

## Decisiones tecnicas y alternativas descartadas
1. Se mantuvo separacion IaC/runtime:
   - Terraform crea recursos estables (role, pipeline, model package group),
   - la ejecucion del pipeline crea jobs y versiones de modelo.
2. Se corrigio el contrato tecnico de pipeline para execution real:
   - `AccuracyThreshold` en `ContainerArguments` se forzo a string con `Std:Join`.
3. Se corrigio imagen de entrenamiento para `eu-west-1`:
   - `training_image_uri` -> `141502667606.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-xgboost:1.7-1`.
4. Se separo imagen de evaluacion:
   - `processing_image_uri` se mantiene en sklearn para preprocess,
   - `evaluation_image_uri` usa XGBoost para soportar `import xgboost` en `evaluate.py`.
5. Se corrigio formato de entradas de entrenamiento:
   - `preprocess.py` deja solo `train_xgb.csv` y `validation_xgb.csv`.
6. Se manejo cache/stale artifacts:
   - limpieza de `pipeline/runtime/.../preprocess/*` y relanzado con `CodeBundleUri` nuevo.
7. Se valido operacion con retry:
   - `RetryPipelineExecution` aplicado sobre ejecucion fallida tras fixes IAM.
8. Se alineo el tutorial de fase 03 con incidentes reales:
   - assert de version SDK v3 robusto,
   - imagen de evaluacion separada (`evaluation_image_uri`),
   - semantica de retry (misma ejecucion/version),
   - runbook de limpieza de prefijos preprocess,
   - permisos IAM minimos explicitados.
9. Alternativas descartadas:
   - mantener imagen antigua no accesible de ECR,
   - mantener evaluacion en imagen sklearn sin `xgboost`,
   - desactivar cache globalmente (se prefirio invalidacion controlada por parametro + limpieza puntual).

## IAM usado (roles/policies/permisos clave)
1. Identidad humana operativa: `arn:aws:iam::939122281183:user/data-science-user`.
2. Perfil AWS CLI: `data-science-user`.
3. Role de ejecucion pipeline: `arn:aws:iam::939122281183:role/titanic-sagemaker-pipeline-dev`.
4. Permisos ajustados en esta iteracion:
   - `s3:GetObject` en `arn:aws:s3:::<data_bucket>/pipeline/runtime/*` para consumo de artefactos entre steps,
   - `sagemaker:CreateModelPackageGroup` para `RegisterModel`.

## Comandos ejecutados y resultado esperado
1. Aplicar infraestructura fase 03:
```bash
AWS_PROFILE=data-science-user terraform -chdir=terraform/03_sagemaker_pipeline apply -auto-approve \
  -var='data_bucket_name=titanic-data-bucket-939122281183-data-science-user' \
  -var='code_bundle_uri=s3://titanic-data-bucket-939122281183-data-science-user/pipeline/code/eb9b1b5/pipeline_code.tar.gz'
```
Esperado: pipeline y role actualizados con fixes.

2. Ejecutar pipeline:
```bash
AWS_PROFILE=data-science-user aws sagemaker start-pipeline-execution \
  --pipeline-name titanic-modelbuild-dev --region eu-west-1
```
Esperado: `PipelineExecutionArn` valido.

3. Monitorear steps:
```bash
AWS_PROFILE=data-science-user aws sagemaker list-pipeline-execution-steps \
  --pipeline-execution-arn <execution_arn> --region eu-west-1
```
Esperado: visibilidad de `DataPreProcessing`, `TrainModel`, `ModelEvaluation`, `QualityGateAccuracy`, `RegisterModel`.

4. Retry de ejecucion tras fix IAM:
```bash
AWS_PROFILE=data-science-user aws sagemaker retry-pipeline-execution \
  --pipeline-execution-arn arn:aws:sagemaker:eu-west-1:939122281183:pipeline/titanic-modelbuild-dev/execution/nml8kzcszw3w \
  --region eu-west-1
```
Esperado: registro final exitoso sin recomputar pasos previos innecesarios.

5. Verificar registro de modelo:
```bash
AWS_PROFILE=data-science-user aws sagemaker list-model-packages \
  --model-package-group-name titanic-survival-xgboost \
  --sort-by CreationTime --sort-order Descending --max-results 5 --region eu-west-1
```
Esperado: version registrada con `PendingManualApproval`.

6. Verificar que la guia de fase 03 incluye fixes operativos:
```bash
rg -n 'evaluation_image_uri|CreateModelPackageGroup|RetryPipelineExecution|runbook|importlib.metadata' docs/tutorials/03-sagemaker-pipeline.md
```
Esperado: aparicion explicita de los cambios en tutorial.

## Evidencia
1. Ejecucion final validada:
   - `PipelineExecutionArn`: `arn:aws:sagemaker:eu-west-1:939122281183:pipeline/titanic-modelbuild-dev/execution/nml8kzcszw3w`
   - `PipelineExecutionStatus`: `Succeeded`
   - `PipelineVersionId`: `3`
2. Estado por step (final):
   - `DataPreProcessing`: `Succeeded`
   - `TrainModel`: `Succeeded`
   - `ModelEvaluation`: `Succeeded`
   - `QualityGateAccuracy`: `Succeeded`
   - `RegisterModel-RegisterModel`: `Succeeded`
3. Modelo registrado:
   - `ModelPackageArn`: `arn:aws:sagemaker:eu-west-1:939122281183:model-package/titanic-survival-xgboost/1`
   - `ModelApprovalStatus`: `PendingManualApproval`
4. Causa raiz y correcciones aplicadas durante incidentes:
   - ECR image no accesible -> URI de entrenamiento corregida.
   - `AccessDenied s3:GetObject` en runtime prefix -> policy ampliada.
   - CSV parser error por archivos legacy en prefijo de validacion -> limpieza S3 + ajuste `preprocess.py`.
   - `ModuleNotFoundError: xgboost` en evaluacion -> `evaluation_image_uri` dedicada.
   - `CreateModelPackageGroup` denegado -> permiso agregado y retry exitoso.
5. Tutorial actualizado con runbook y guardrails que reflejan la operacion real de esta iteracion.

## Riesgos/pendientes
1. Los outputs de preprocess usan prefijos S3 estables; si se agregan archivos auxiliares en esos prefijos, XGBoost puede romper parseo.
2. Falta automatizar limpieza/aislamiento por ejecucion (prefijos por `ExecutionId`) para eliminar riesgo de artefactos heredados.
3. Aun no se promovio modelo (`Approved`) ni se despliega endpoint (fase 04).

## Proximo paso
1. Endurecer pipeline para outputs por ejecucion (evitar colision en `preprocess/*`).
2. Definir gate de aprobacion manual y promocion controlada a serving en fase 04.
3. Integrar esta validacion en CI/CD (plan/apply + smoke execution de pipeline en `dev`).
